---
title: "BACS HW (Week 17)"
author: '108020024'
date: "due on 06/11 (Sun) Helped by 108020033"
output:
  pdf_document:
     latex_engine: xelatex

  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE) 

```

### Question 1) Create some explanatory models to learn more about charges:



```{r}
# Load the data and remove missing values
insurance <- read.csv("insurance.csv")
insurance <- na.omit(insurance)
```

### a) Create an OLS regression model and report which factors are significantly related to charges

```{r}
md1=lm(charges~age+sex+bmi+children+smoker+factor(region),data = insurance)

summary(md1)

```

Age, bmi, children, smokeryes, (region)southeast, (region)southwest are significantly related to charges.

### b) Create a decision tree (specifically, a regression tree) with default parameters to rpart().

```{r}

library(rpart)
library(rpart.plot)

md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),data = insurance)

```

### i) Plot a visual representation of the tree structure

```{r}

rpart.plot(md2)
```

### ii) How deep is the tree (see nodes with “decisions” – ignore the leaves at the bottom)

2 levels.

### iii) How many leaf groups does it suggest to bin the data into?

4 groups.

### iv) What conditions (combination of decisions) describe each leaf group?

For the left two leafs, if the person is a smoker and over 43 years old, it goes to the left leaf. Older than 43 years old, goes to right leaf.


For the right two leafs, if the person is not a smoker and bmi is less than 30, it goes to the left leaf. Bmi is more than 30, goes to right leaf.

### Question 2) Let’s use LOOCV to see how how our models perform predictively overall

### a) What is the RMSEout for the OLS regression model?

```{r}
library(caret)
train_control <- trainControl(method = "LOOCV") # LOOCV

# training the model by assigning "column Y"
model <- train(charges~age+sex+bmi+children+smoker+factor(region),data = insurance,
               method = "lm",   # linear model
               trControl = train_control) # training control data
 
# printing model performance metrics
print(model)

```


### b) What is the RMSEout for the decision tree model?

The default cp is 0.01, control it in the model.
```{r}
library(caret)
train_control <- trainControl(method = "LOOCV") # LOOCV

# training the model by assigning "column Y"
model <- train(charges~age+sex+bmi+children+smoker+factor(region),data = insurance,
               method = "rpart",
               tuneGrid=expand.grid(cp = seq(0.01)),
               trControl = train_control) # training control data
 
# printing model performance metrics
print(model)

```

### Question 3) Let’s see if bagging helps our models

### a) Implement the bagged_learn(…) and bagged_predict(…) functions using the hints in the class notes and help from your classmates on Teams. Feel free to share your code on Teams to get feedback, or ask others for help.


```{r}
set.seed(123) 


sample <- sample(c(TRUE, FALSE), nrow(insurance), replace=TRUE, prob=c(0.8,0.2))
training_set  <- insurance[sample, ]
testing_set   <- insurance[!sample, ]


bagged_learn=function(model,dataset,b=100){
  lapply(1:b,\(i){
    boot_index=sample(1:nrow(dataset),nrow(dataset),replace=T)    
    boot_dataset=dataset[boot_index,]   
    boot_model=update(model,data=boot_dataset)
    return(boot_model)   
  })
}


bagged_predict <- function(bagged_models, new_data,b=100) {
  predictions=lapply(1:b,\(i){
    predict(bagged_models[[i]],new_data)
  })
  apply(as.data.frame(predictions),1,mean)
}


```

### b) What is the RMSEout for the bagged OLS regression?


```{r}
bagged_model = bagged_learn(md1,training_set, b = 100)

bagged_predictions=bagged_predict(bagged_model,testing_set)

rmse_oos=function(actuals,preds){
  sqrt(mean((actuals-preds)^2)) 
}  

rmse_oos(testing_set$charges,unlist(bagged_predictions))

```

### c) What is the RMSEout for the bagged decision tree?


```{r}
bagged_learn(md2,insurance,b=100)|>
  bagged_predict(testing_set)|> 
  rmse_oos(testing_set$charges)

```



### Question 4) Let’s see if boosting helps our models. You can use a learning rate of 0.1 and adjust it if you find a better rate.


### a) Write boosted_learn(…) and boosted_predict(…) functions using the hints in the class notes and help from your classmates on Teams. Feel free to share your code generously on Teams to get feedback, or ask others for help.



```{r}


boost_learn=function(model,dataset,outcome,n=100,rate=0.1){
  predictors=dataset[,!names(dataset) %in% c(outcome)]
  res=dataset[,outcome]
  models=list()
  for(i in 1:n){ 
    this_model=update(model,data=cbind(charges=res,predictors))
    res=res-(rate*predict(this_model,dataset))
    models[[i]]=this_model
  } 
  list(models=models,rate=rate)
}

boost_predict=function(boosted_learning,new_data){
  boosted_models=boosted_learning$models
  rate=boosted_learning$rate
  n=length(boosted_learning$models)
  predictions=lapply(1:n, \(i){
    rate*predict(boosted_models[[i]],new_data)
  })
  pred_frame=as.data.frame(predictions)|>unname()
  apply(pred_frame,1,sum)
}

```

### b) What is the RMSEout for the boosted OLS regression?

```{r}

boosted_model=boost_learn(md1,training_set,"charges",n=100,rate=0.1)
boosted_predictions=boost_predict(boosted_model,testing_set) 
rmse_oos(testing_set$charges,unlist(boosted_predictions))
```

### c) What is the RMSEout for the boosted decision tree?

```{R}

boost_learn(md2,insurance,"charges",n=100)|> 
  boost_predict(testing_set)|>
  rmse_oos(testing_set$charges)
```


### Question 5) Let’s engineer the best predictive decision trees. Let’s repeat the bagging and boosting decision tree several times to see what kind of base tree helps us learn the fastest. But this time, split the data 70:20:10 — use 70% for training, 20% for fine-tuning, and use the last 10% to report the final RMSEout.
```{R}
set.seed(123) 


sample <- sample(c(TRUE, FALSE), nrow(insurance), replace=TRUE, prob=c(0.7,0.3))
training_set  <- insurance[sample, ]
temp   <- insurance[!sample, ]


sample <- sample(c(TRUE, FALSE), nrow(temp), replace=TRUE, prob=c(2/3,1/3))
tuneing_set  <- temp[sample, ]
testing_set   <- temp[!sample, ]


```


### a) Repeat the bagging of the decision tree, using a base tree of maximum depth 1, 2, … n, keep training on the 70% training set while the RMSEout of your 20% set keeps dropping; stop when the RMSEout has started increasing again (show prediction error at each depth). Report the final RMSEout using the final 10% of the data as your test set.

```{R}
ctrl = rpart.control(maxdepth=1)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

bagged_learn(md2,insurance,b=100)|>
  bagged_predict(tuneing_set)|> 
  rmse_oos(tuneing_set$charges)

```

```{R}
ctrl = rpart.control(maxdepth=2)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

bagged_learn(md2,insurance,b=100)|>
  bagged_predict(tuneing_set)|> 
  rmse_oos(tuneing_set$charges)

```

```{R}
ctrl = rpart.control(maxdepth=3)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

bagged_learn(md2,insurance,b=100)|>
  bagged_predict(tuneing_set)|> 
  rmse_oos(tuneing_set$charges)

```
```{R}
ctrl = rpart.control(maxdepth=4)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

bagged_learn(md2,insurance,b=100)|>
  bagged_predict(tuneing_set)|> 
  rmse_oos(tuneing_set$charges)

```

max depth is 4

```{R}
ctrl = rpart.control(maxdepth=4)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

bagged_learn(md2,insurance,b=100)|>
  bagged_predict(testing_set)|> 
  rmse_oos(testing_set$charges)

```

Final RMSEout is 4555.802.

### b) Repeat the boosting of the decision tree, using a base tree of maximum depth 1, 2, … n, keep training on the 70% training set while the RMSEout of your 20% set keeps dropping; stop when the RMSEout has started increasing again (show prediction error at each depth). Report the final RMSEout using the final 10% of the data as your test set.


```{R}
ctrl = rpart.control(maxdepth=1)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

boost_learn(md2,insurance,"charges",n=100)|> 
  boost_predict(tuneing_set)|>
  rmse_oos(tuneing_set$charges)
```
```{R}
ctrl = rpart.control(maxdepth=2)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

boost_learn(md2,insurance,"charges",n=100)|> 
  boost_predict(tuneing_set)|>
  rmse_oos(tuneing_set$charges)
```

```{R}
ctrl = rpart.control(maxdepth=3)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

boost_learn(md2,insurance,"charges",n=100)|> 
  boost_predict(tuneing_set)|>
  rmse_oos(tuneing_set$charges)
```

```{R}
ctrl = rpart.control(maxdepth=4)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

boost_learn(md2,insurance,"charges",n=100)|> 
  boost_predict(tuneing_set)|>
  rmse_oos(tuneing_set$charges)
```


max depth is 4

```{R}
ctrl = rpart.control(maxdepth=4)
md2=rpart(charges~age+factor(sex)+bmi+children+factor(smoker)+factor(region),control=ctrl,data = insurance)

boost_learn(md2,insurance,"charges",n=100)|> 
  boost_predict(testing_set)|>
  rmse_oos(testing_set$charges)

```

Final RMSEout is 4052.252.